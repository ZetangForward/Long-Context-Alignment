{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/zecheng/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.54s/it]\n",
      "Unloading and merging model: 100%|██████████| 550/550 [00:00<00:00, 2152.08it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-14 19:54:39,298] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/zecheng/compiler_compat/ld: cannot find -laio: 没有那个文件或目录\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-devel package with yum\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/nvme/zecheng/ckpt/v3/tokenizer_config.json',\n",
       " '/nvme/zecheng/ckpt/v3/special_tokens_map.json',\n",
       " '/nvme/zecheng/ckpt/v3/tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_id, model_id = \"/nvme/zecheng/ckpt/simpo-sft-16k-80k-v3/checkpoint-200/context_scaling\", \"/data/zecheng/hf_models/Llama-3-8B-Instruct-80K-QLoRA-Merged\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\"\n",
    ")\n",
    "\n",
    "adapter = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    peft_id,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\"\n",
    ")\n",
    "\n",
    "model = adapter.merge_and_unload(progressbar=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id) #, use_fast=False)\n",
    "\n",
    "model.save_pretrained(\"/nvme/zecheng/ckpt/v3\")\n",
    "\n",
    "tokenizer.save_pretrained(\"/nvme/zecheng/ckpt/v3\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
